{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5323dee2-fc69-4446-b99d-1f01a51a3515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a18069b-07ef-488e-b6b3-4d2568c1e65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_equalization(img):\n",
    "    \"\"\"Apply histogram equalization to enhance contrast.\"\"\"\n",
    "    img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "    img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])\n",
    "    return cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "\n",
    "def adaptive_histogram_equalization(img, clip_limit=2.0, tile_grid_size=(8, 8)):\n",
    "    \"\"\"Apply CLAHE (Contrast Limited Adaptive Histogram Equalization).\"\"\"\n",
    "    img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    img_yuv[:,:,0] = clahe.apply(img_yuv[:,:,0])\n",
    "    return cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)\n",
    "\n",
    "def gamma_correction(img, gamma=1.5):\n",
    "    \"\"\"Apply gamma correction to adjust brightness.\"\"\"\n",
    "    inv_gamma = 1.0 / gamma\n",
    "    table = np.array([(i / 255.0) ** inv_gamma * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "    return cv2.LUT(img, table)\n",
    "\n",
    "def contrast_stretching(img):\n",
    "    \"\"\"Apply simple contrast stretching.\"\"\"\n",
    "    min_val, max_val = np.min(img), np.max(img)\n",
    "    stretched = (img - min_val) * (255.0 / (max_val - min_val))\n",
    "    return stretched.astype(np.uint8)\n",
    "\n",
    "def enhance_low_light_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(\"Error: Unable to read image.\")\n",
    "        return\n",
    "    \n",
    "    hist_eq = histogram_equalization(img)\n",
    "    adaptive_hist_eq = adaptive_histogram_equalization(img)\n",
    "    gamma_corrected = gamma_correction(img)\n",
    "    contrast_stretched = contrast_stretching(img)\n",
    "    \n",
    "    cv2.imshow(\"Original\", img)\n",
    "    cv2.imshow(\"Histogram Equalization\", hist_eq)\n",
    "    cv2.imshow(\"Adaptive Histogram Equalization (CLAHE)\", adaptive_hist_eq)\n",
    "    cv2.imshow(\"Gamma Correction\", gamma_corrected)\n",
    "    cv2.imshow(\"Contrast Stretching\", contrast_stretched)\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4994202d-d125-41dc-bd2a-5a39ea8dc9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-19 13:09:52.019 python[38960:38491600] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-02-19 13:09:52.019 python[38960:38491600] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "enhance_low_light_image(\"./lol_dataset/our485/low/747.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d49527-390d-41d3-b033-5e9fde6bd11c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
