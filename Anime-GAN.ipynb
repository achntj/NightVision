{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4aeff1d-ea0e-40d9-aa63-a571d989c1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/AK391/animegan2-pytorch/zipball/main\" to /Users/achintyajha/.cache/torch/hub/main.zip\n",
      "Downloading: \"https://github.com/bryandlee/animegan2-pytorch/raw/main/weights/face_paint_512_v2.pt\" to /Users/achintyajha/.cache/torch/hub/checkpoints/face_paint_512_v2.pt\n",
      "100%|██████████████████████████████████████| 8.20M/8.20M [00:00<00:00, 26.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "\n",
    "# Load a pre-trained model for low-light enhancement from TorchHub\n",
    "model = torch.hub.load('AK391/animegan2-pytorch', 'generator', pretrained=True, trust_repo=True)\n",
    "model.eval()\n",
    "\n",
    "# Image preprocessing\n",
    "def preprocess_image(image_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transform(image).unsqueeze(0)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "# Image post-processing\n",
    "def postprocess_image(tensor):\n",
    "    tensor = tensor.squeeze(0).detach().cpu().numpy()\n",
    "    tensor = np.transpose(tensor, (1, 2, 0))  # CHW -> HWC\n",
    "    tensor = (tensor - tensor.min()) / (tensor.max() - tensor.min()) * 255  # Normalize\n",
    "    return tensor.astype(np.uint8)\n",
    "\n",
    "# Enhance image\n",
    "def enhance_image(image_path, output_path):\n",
    "    image = preprocess_image(image_path)\n",
    "    with torch.no_grad():\n",
    "        enhanced_image = model(image)\n",
    "    enhanced_image = postprocess_image(enhanced_image)\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(enhanced_image, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e53df3a2-faf9-4003-bcaf-381bb06f9903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "enhance_image(\"./lol_dataset/our485/low/2.png\", \"enhanced_output.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae6e09c-dc30-4df8-85e2-1c35f99d3d27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
